{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Pytorch Baseline - Train\n",
    "\n",
    "**Notes**\n",
    "- Do not forget to enable the GPU (TPU) for training\n",
    "- You have to add `kaggle_l5kit` as utility script\n",
    "- Parts of the code below is from the [official example](https://github.com/lyft/l5kit/blob/master/examples/agent_motion_prediction/agent_motion_prediction.ipynb)\n",
    "- [Baseline inference notebook](https://www.kaggle.com/pestipeti/pytorch-baseline-inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ma\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet18,resnet50,resnet101\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "from pykalman import AdditiveUnscentedKalmanFilter\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_INPUT = \"/media/ubuntu/Data/project/lyft/lyft-motion-prediction-autonomous-vehicles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'model_params': {\n",
    "        'history_num_frames': 100,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1\n",
    "    },\n",
    "    \n",
    "    'raster_params': {\n",
    "        'raster_size': [1, 1],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 8,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning, you're running with a custom agents_mask\n"
     ]
    }
   ],
   "source": [
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "test_zarr = ChunkedDataset(dm.require(cfg['test_data_loader'][\"key\"])).open()\n",
    "test_mask = np.load(f\"{DIR_INPUT}/scenes/mask.npz\")[\"arr_0\"]\n",
    "test_dataset = AgentDataset(cfg, test_zarr, rasterizer, agents_mask=test_mask)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             shuffle=False, \n",
    "                             batch_size=cfg['test_data_loader'][\"batch_size\"], \n",
    "                             num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MotionModel(currentState,ang_rng=None):\n",
    "    nextState    = np.zeros(6)\n",
    "    nextState[0] = currentState[0] +  np.cos(currentState[3]) *  currentState[2]# * deltaTimeStamp + 0.5 * currentState[5]* (deltaTimeStamp**2) ) \n",
    "    nextState[1] = currentState[1] +  np.sin(currentState[3]) *  currentState[2] # * deltaTimeStamp + 0.5 * currentState[5]* (deltaTimeStamp**2) ) \n",
    "    nextState[2] = currentState[2] +  currentState[5] \n",
    "    nextState[3] = currentState[3] +  currentState[4]                                                                                                            \n",
    "    if ang_rng is not None:\n",
    "        nextState[3] = np.clip(nextState[3], ang_rng[0], ang_rng[1])                                                                \n",
    "    nextState[4] = currentState[4]                                                                                                                     \n",
    "    nextState[5] = currentState[5]  * 0.9                                                                                                                    \n",
    "    return nextState\n",
    "\n",
    "def MeasurementModel(currentState):\n",
    "    measureState = np.zeros(3)\n",
    "    measureState[0] = currentState[0]\n",
    "    measureState[1] = currentState[1]\n",
    "    measureState[2] = currentState[3]\n",
    "    return measureState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def f(cs, ang_rng=None):\n",
    "    res = np.zeros(6)\n",
    "    res[0] = cs[0] + cs[2]*np.cos(cs[3])\n",
    "    res[1] = cs[1] + cs[2]*np.sin(cs[3])\n",
    "    res[2] = cs[2] + cs[5]\n",
    "    res[3] = cs[3] + cs[4]\n",
    "    if ang_rng is not None:\n",
    "        res[3] = np.clip(res[3], ang_rng[0], ang_rng[1])\n",
    "    res[4] = cs[4]\n",
    "    res[5] = 0.9*cs[5]\n",
    "    return res\n",
    "\n",
    "def g(cs):\n",
    "    res = np.zeros(2)\n",
    "    res[0] = cs[0]\n",
    "    res[1] = cs[1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timestamps = []\n",
    "agent_ids = []\n",
    "future_coords_offsets_pd = []\n",
    "\n",
    "for batch_idx, data in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "    history_positions = data['history_positions'].cpu().numpy()\n",
    "    history_yaws = data['history_yaws'].cpu().numpy()\n",
    "    history_availabilities = data['history_availabilities'].cpu().numpy()\n",
    "    timestamp = data[\"timestamp\"].cpu().numpy()\n",
    "    track_id = data[\"track_id\"].cpu().numpy()\n",
    "    \n",
    "    def KalmanfilterExec(historyPostion,historyYaw,historyAvailability,timeStamp,trackId):\n",
    "\n",
    "        measurements = historyPostion[::-1]\n",
    "        #measurements = np.hstack( (measurements,historyYaw[::-1] )) \n",
    "\n",
    "        ang_std = 0.01\n",
    "        Q = 0.001*np.diag([1, 1,ang_std**2, ang_std**2, 1, 0.001])\n",
    "        m0 = measurements[-1]\n",
    "\n",
    "        kf = AdditiveUnscentedKalmanFilter(initial_state_mean = [m0[0],m0[1],0,0,0,0], \n",
    "                                           n_dim_obs=2,\n",
    "                                           transition_functions = MotionModel,\n",
    "                                           observation_functions = MeasurementModel,\n",
    "                                           transition_covariance = Q,\n",
    "                                           initial_state_covariance = Q,\n",
    "                                           observation_covariance = 0.1**2*np.eye(2))\n",
    "\n",
    "        previousSate = ma.array(measurements)\n",
    "        previousSate[historyAvailability[::-1] < 0.5] = ma.masked\n",
    "\n",
    "        z = kf.smooth(previousSate)\n",
    "\n",
    "        prediction = np.zeros((51,6))\n",
    "        prediction[0] = z[0][-1]\n",
    "        ang_rng = (z[0][-10:,3].min() - math.pi/3, z[0][-10:,3].max() + math.pi/3)\n",
    "        for i in range(1,51):\n",
    "            prediction[i] = MotionModel(prediction[i-1], ang_rng)\n",
    "        prediction = prediction[1:,:2]\n",
    "        \n",
    "        return timeStamp, trackId, np.expand_dims(prediction,0)\n",
    "\n",
    "    res = Parallel(n_jobs=4)(delayed(KalmanfilterExec)(history_positions[i], history_yaws[i],history_availabilities[i], \n",
    "                                          timestamp[i], track_id[i]) for i in range(len(data['history_positions'])))\n",
    "    \n",
    "    timestamps.append(np.stack([r[0] for r in res]))\n",
    "    agent_ids.append(np.stack([r[1] for r in res]))\n",
    "    future_coords_offsets_pd.append(np.concatenate([r[2] for r in res]))\n",
    "\n",
    "print(np.concatenate(future_coords_offsets_pd).shape)\n",
    "write_pred_csv(\"/media/ubuntu/Data/project/lyft/l5kit-1.0.6/examples/agent_motion_prediction/submission_KF_new.csv\",\n",
    "       timestamps=np.concatenate(timestamps),\n",
    "       track_ids=np.concatenate(agent_ids),\n",
    "       coords=np.concatenate(future_coords_offsets_pd),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8891/8891 [3:53:07<00:00,  1.57s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71122, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "timestamps = []\n",
    "agent_ids = []\n",
    "future_coords_offsets_pd = []\n",
    "\n",
    "for batch_idx, data in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "    history_positions = data['history_positions'].cpu().numpy()\n",
    "    history_yaws = data['history_yaws'].cpu().numpy()\n",
    "    history_availabilities = data['history_availabilities'].cpu().numpy()\n",
    "    timestamp = data[\"timestamp\"].cpu().numpy()\n",
    "    track_id = data[\"track_id\"].cpu().numpy()\n",
    "    \n",
    "    def run(hp,hy,ha,ts,ti):\n",
    "\n",
    "        measurements = hp[::-1]\n",
    "        measurements = np.hstack( (measurements,hy[::-1] )) \n",
    "\n",
    "        ang_std = 0.01\n",
    "        Q = 0.001*np.diag([1, 1, 1, ang_std**2, ang_std**2, 0.001])\n",
    "        m0 = measurements[-1]\n",
    "\n",
    "        kf = AdditiveUnscentedKalmanFilter(initial_state_mean = [m0[0],m0[1],0,m0[2],0,0], \n",
    "                                           n_dim_obs=3,\n",
    "                                           transition_functions = MotionModel,\n",
    "                                           observation_functions = MeasurementModel,\n",
    "                                           transition_covariance = Q,\n",
    "                                           initial_state_covariance = Q,\n",
    "                                           observation_covariance = 0.1**2*np.eye(3))\n",
    "\n",
    "        X = ma.array(measurements)\n",
    "        X[ha[::-1] < 0.5] = ma.masked\n",
    "\n",
    "        z = kf.smooth(X)\n",
    "\n",
    "        pred = np.zeros((51,6))\n",
    "        pred[0] = z[0][-1]\n",
    "        ang_rng = (z[0][-10:,3].min() - math.pi/3, z[0][-10:,3].max() + math.pi/3)\n",
    "        for i in range(1,51):\n",
    "            pred[i] = MotionModel(pred[i-1], ang_rng)\n",
    "        pred = pred[1:,:2]\n",
    "        \n",
    "        return ts, ti, np.expand_dims(pred,0)\n",
    "\n",
    "    res = Parallel(n_jobs=4)(delayed(run)(history_positions[i], history_yaws[i],history_availabilities[i], \n",
    "                                          timestamp[i], track_id[i]) for i in range(len(data['history_positions'])))\n",
    "    \n",
    "    timestamps.append(np.stack([r[0] for r in res]))\n",
    "    agent_ids.append(np.stack([r[1] for r in res]))\n",
    "    future_coords_offsets_pd.append(np.concatenate([r[2] for r in res]))\n",
    "\n",
    "print(np.concatenate(future_coords_offsets_pd).shape)\n",
    "write_pred_csv(\"/media/ubuntu/Data/project/lyft/l5kit-1.0.6/examples/agent_motion_prediction/submission_KF_1.csv\",\n",
    "       timestamps=np.concatenate(timestamps),\n",
    "       track_ids=np.concatenate(agent_ids),\n",
    "       coords=np.concatenate(future_coords_offsets_pd),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
