{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Pytorch Baseline - Train\n",
    "\n",
    "**Notes**\n",
    "- Do not forget to enable the GPU (TPU) for training\n",
    "- You have to add `kaggle_l5kit` as utility script\n",
    "- Parts of the code below is from the [official example](https://github.com/lyft/l5kit/blob/master/examples/agent_motion_prediction/agent_motion_prediction.ipynb)\n",
    "- [Baseline inference notebook](https://www.kaggle.com/pestipeti/pytorch-baseline-inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ma\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet18,resnet50,resnet101\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "from pykalman import AdditiveUnscentedKalmanFilter\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_INPUT = \"/media/ubuntu/Data/project/lyft/lyft-motion-prediction-autonomous-vehicles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'model_params': {\n",
    "        'history_num_frames': 100,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1\n",
    "    },\n",
    "    \n",
    "    'raster_params': {\n",
    "        'raster_size': [1, 1],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 8,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning, you're running with a custom agents_mask\n"
     ]
    }
   ],
   "source": [
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "test_zarr = ChunkedDataset(dm.require(cfg['test_data_loader'][\"key\"])).open()\n",
    "test_mask = np.load(f\"{DIR_INPUT}/scenes/mask.npz\")[\"arr_0\"]\n",
    "test_dataset = AgentDataset(cfg, test_zarr, rasterizer, agents_mask=test_mask)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             shuffle=False, \n",
    "                             batch_size=cfg['test_data_loader'][\"batch_size\"], \n",
    "                             num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MotionModel(currentState,ang_rng=None):\n",
    "    nextState    = np.zeros(6)\n",
    "    nextState[0] = currentState[0] +  np.cos(currentState[3]) *  currentState[2]# * deltaTimeStamp + 0.5 * currentState[5]* (deltaTimeStamp**2) ) \n",
    "    nextState[1] = currentState[1] +  np.sin(currentState[3]) *  currentState[2] # * deltaTimeStamp + 0.5 * currentState[5]* (deltaTimeStamp**2) ) \n",
    "    nextState[2] = currentState[2] +  currentState[5] \n",
    "    nextState[3] = currentState[3] +  currentState[4]                                                                                                            \n",
    "    if ang_rng is not None:\n",
    "        nextState[3] = np.clip(nextState[3], ang_rng[0], ang_rng[1])                                                                \n",
    "    nextState[4] = currentState[4]                                                                                                                     \n",
    "    nextState[5] = currentState[5]  * 0.9                                                                                                                    \n",
    "    return nextState\n",
    "\n",
    "def MeasurementModel(currentState):\n",
    "    measureState = np.zeros(2)\n",
    "    measureState[0] = currentState[0]\n",
    "    measureState[1] = currentState[1]\n",
    "    #measureState[2] = currentState[3]\n",
    "    return measureState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def f(cs, ang_rng=None):\n",
    "    res = np.zeros(6)\n",
    "    res[0] = cs[0] + cs[2]*np.cos(cs[3])\n",
    "    res[1] = cs[1] + cs[2]*np.sin(cs[3])\n",
    "    res[2] = cs[2] + cs[5]\n",
    "    res[3] = cs[3] + cs[4]\n",
    "    if ang_rng is not None:\n",
    "        res[3] = np.clip(res[3], ang_rng[0], ang_rng[1])\n",
    "    res[4] = cs[4]\n",
    "    res[5] = 0.9*cs[5]\n",
    "    return res\n",
    "\n",
    "def g(cs):\n",
    "    res = np.zeros(2)\n",
    "    res[0] = cs[0]\n",
    "    res[1] = cs[1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timestamps = []\n",
    "agent_ids = []\n",
    "future_coords_offsets_pd = []\n",
    "\n",
    "for batch_idx, data in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "    history_positions = data['history_positions'].cpu().numpy()\n",
    "    history_yaws = data['history_yaws'].cpu().numpy()\n",
    "    history_availabilities = data['history_availabilities'].cpu().numpy()\n",
    "    timestamp = data[\"timestamp\"].cpu().numpy()\n",
    "    track_id = data[\"track_id\"].cpu().numpy()\n",
    "    \n",
    "    def KalmanfilterExec(historyPostion,historyYaw,historyAvailability,timeStamp,trackId):\n",
    "\n",
    "        measurements = historyPostion[::-1]\n",
    "        #measurements = np.hstack( (measurements,historyYaw[::-1] )) \n",
    "\n",
    "        ang_std = 0.01\n",
    "        Q = 0.001*np.diag([1, 1,ang_std**2, ang_std**2, 1, 0.001])\n",
    "        m0 = measurements[-1]\n",
    "\n",
    "        kf = AdditiveUnscentedKalmanFilter(initial_state_mean = [m0[0],m0[1],0,0,0,0], \n",
    "                                           n_dim_obs=2,\n",
    "                                           transition_functions = MotionModel,\n",
    "                                           observation_functions = MeasurementModel,\n",
    "                                           transition_covariance = Q,\n",
    "                                           initial_state_covariance = Q,\n",
    "                                           observation_covariance = 0.1**2*np.eye(2))\n",
    "\n",
    "        previousSate = ma.array(measurements)\n",
    "        previousSate[historyAvailability[::-1] < 0.5] = ma.masked\n",
    "\n",
    "        z = kf.smooth(previousSate)\n",
    "\n",
    "        prediction = np.zeros((51,6))\n",
    "        prediction[0] = z[0][-1]\n",
    "        ang_rng = (z[0][-10:,3].min() - math.pi/3, z[0][-10:,3].max() + math.pi/3)\n",
    "        for i in range(1,51):\n",
    "            prediction[i] = MotionModel(prediction[i-1], ang_rng)\n",
    "        prediction = prediction[1:,:2]\n",
    "        \n",
    "        return timeStamp, trackId, np.expand_dims(prediction,0)\n",
    "\n",
    "    res = Parallel(n_jobs=4)(delayed(KalmanfilterExec)(history_positions[i], history_yaws[i],history_availabilities[i], \n",
    "                                          timestamp[i], track_id[i]) for i in range(len(data['history_positions'])))\n",
    "    \n",
    "    timestamps.append(np.stack([r[0] for r in res]))\n",
    "    agent_ids.append(np.stack([r[1] for r in res]))\n",
    "    future_coords_offsets_pd.append(np.concatenate([r[2] for r in res]))\n",
    "\n",
    "print(np.concatenate(future_coords_offsets_pd).shape)\n",
    "write_pred_csv(\"/media/ubuntu/Data/project/lyft/l5kit-1.0.6/examples/agent_motion_prediction/submission_KF_new.csv\",\n",
    "       timestamps=np.concatenate(timestamps),\n",
    "       track_ids=np.concatenate(agent_ids),\n",
    "       coords=np.concatenate(future_coords_offsets_pd),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8891 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/media/ubuntu/Data/tools/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/media/ubuntu/Data/tools/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/media/ubuntu/Data/tools/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/media/ubuntu/Data/tools/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/media/ubuntu/Data/tools/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-8-745416272ed5>\", line 34, in run\nIndexError: index 2 is out of bounds for axis 0 with size 2\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-745416272ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     res = Parallel(n_jobs=4)(delayed(run)(history_positions[i], history_yaws[i],history_availabilities[i], \n\u001b[0;32m---> 57\u001b[0;31m                                           timestamp[i], track_id[i]) for i in range(len(data['history_positions'])))\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtimestamps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ubuntu/Data/tools/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ubuntu/Data/tools/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ubuntu/Data/tools/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ubuntu/Data/tools/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ubuntu/Data/tools/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "timestamps = []\n",
    "agent_ids = []\n",
    "future_coords_offsets_pd = []\n",
    "\n",
    "for batch_idx, data in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "    history_positions = data['history_positions'].cpu().numpy()\n",
    "    history_yaws = data['history_yaws'].cpu().numpy()\n",
    "    history_availabilities = data['history_availabilities'].cpu().numpy()\n",
    "    timestamp = data[\"timestamp\"].cpu().numpy()\n",
    "    track_id = data[\"track_id\"].cpu().numpy()\n",
    "    \n",
    "    def run(hp,hy,ha,ts,ti):\n",
    "\n",
    "        measurements = hp[::-1]\n",
    "        #measurements = np.hstack( (measurements,hy[::-1] )) \n",
    "\n",
    "        ang_std = 0.01\n",
    "        P_intial = 0.001*np.diag([1, 1, 1, ang_std**2, ang_std**2, 0.001])\n",
    "        Q  = np.zeros((6,6))\n",
    "        deltaTimeStamp=1\n",
    "        Q[0,0] =1\n",
    "        Q[1,1] =1\n",
    "        Q[3,3] = 0.33 * deltaTimeStamp**2 *deltaTimeStamp* 0.017        \n",
    "        Q[3,4] = 0.50 * deltaTimeStamp**2 * 0.017        \n",
    "        Q[4,3] = Q[3,4]\n",
    "        Q[4,4] = deltaTimeStamp * 0.017\n",
    "        Q[2,2] = 0.33 * deltaTimeStamp**2 *deltaTimeStamp* 2.5**2.5\n",
    "        Q[2,5] = 0.50 * deltaTimeStamp**2 * 2.5**2.5\n",
    "        Q[5,2] = Q[2,5]\n",
    "        Q[5,5] = deltaTimeStamp * 2.5**2.5\n",
    "        m0 = measurements[-1]\n",
    "\n",
    "        kf = AdditiveUnscentedKalmanFilter(initial_state_mean = [m0[0],m0[1],0,0,0,0], \n",
    "                                           n_dim_obs=2,\n",
    "                                           transition_functions = MotionModel,\n",
    "                                           observation_functions = MeasurementModel,\n",
    "                                           transition_covariance = Q,\n",
    "                                           initial_state_covariance = P_intial,\n",
    "                                           observation_covariance = 0.1**2*np.eye(2))\n",
    "\n",
    "        X = ma.array(measurements)\n",
    "        X[ha[::-1] < 0.5] = ma.masked\n",
    "\n",
    "        z = kf.smooth(X)\n",
    "\n",
    "        pred = np.zeros((51,6))\n",
    "        pred[0] = z[0][-1]\n",
    "        ang_rng = (z[0][-10:,3].min() - math.pi/3, z[0][-10:,3].max() + math.pi/3)\n",
    "        for i in range(1,51):\n",
    "            pred[i] = MotionModel(pred[i-1], ang_rng)\n",
    "        pred = pred[1:,:2]\n",
    "        \n",
    "        return ts, ti, np.expand_dims(pred,0)\n",
    "\n",
    "    res = Parallel(n_jobs=4)(delayed(run)(history_positions[i], history_yaws[i],history_availabilities[i], \n",
    "                                          timestamp[i], track_id[i]) for i in range(len(data['history_positions'])))\n",
    "    \n",
    "    timestamps.append(np.stack([r[0] for r in res]))\n",
    "    agent_ids.append(np.stack([r[1] for r in res]))\n",
    "    future_coords_offsets_pd.append(np.concatenate([r[2] for r in res]))\n",
    "\n",
    "print(np.concatenate(future_coords_offsets_pd).shape)\n",
    "write_pred_csv(\"/media/ubuntu/Data/project/lyft/l5kit-1.0.6/examples/agent_motion_prediction/submission_KF_3.csv\",\n",
    "       timestamps=np.concatenate(timestamps),\n",
    "       track_ids=np.concatenate(agent_ids),\n",
    "       coords=np.concatenate(future_coords_offsets_pd),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        Q  = np.zeros((6,6))\n",
    "        deltaTimeStamp=1\n",
    "        Q[0,0] =1\n",
    "        Q[1,1] =1\n",
    "        Q[2,2] = 0.33 * deltaTimeStamp**2 *deltaTimeStamp* 0.017\n",
    "        Q[2,3] = 0.50 * deltaTimeStamp**2 * 0.017\n",
    "        Q[3,2] = Q[2,3]\n",
    "        Q[3,3] = deltaTimeStamp * 0.017\n",
    "        Q[4,4] = 0.33 * deltaTimeStamp**2 *deltaTimeStamp* 2.5**2.5\n",
    "        Q[4,5] = 0.50 * deltaTimeStamp**2 * 2.5**2.5\n",
    "        Q[5,4] = Q[4,5]\n",
    "        Q[5,5] = deltaTimeStamp * 2.5**2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.61000000e-03 8.50000000e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.50000000e-03 1.70000000e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.26109884e+00 4.94105884e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.94105884e+00 9.88211769e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "        Q[0,0] =1\n",
    "        Q[1,1] =1\n",
    "        Q[3,3] = 0.33 * deltaTimeStamp**2 *deltaTimeStamp* 0.017        \n",
    "        Q[3,4] = 0.50 * deltaTimeStamp**2 * 0.017        \n",
    "        Q[4,3] = Q[3,4]\n",
    "        Q[4,4] = deltaTimeStamp * 0.017\n",
    "        Q[3,3] = 0.33 * deltaTimeStamp**2 *deltaTimeStamp* 2.5**2.5\n",
    "        Q[3,5] = 0.50 * deltaTimeStamp**2 * 2.5**2.5\n",
    "        Q[5,3] = Q[3,5]\n",
    "        Q[5,5] = deltaTimeStamp * 2.5**2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.61000000e-03 8.50000000e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.50000000e-03 3.26109884e+00\n",
      "  8.50000000e-03 4.94105884e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.50000000e-03\n",
      "  1.70000000e-02 4.94105884e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.94105884e+00\n",
      "  4.94105884e+00 9.88211769e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
